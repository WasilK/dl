{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4733ff8-6e1b-49f5-bb68-df1cbcb66485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dummy dataset created successfully at: C:\\Users\\Acer\\Desktop\\lp4\n",
      "Found 20 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Detected 2 classes: ['cats', 'dogs']\n",
      "\n",
      "ğŸ”¹ Training only new classifier layers...\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.7391 - val_accuracy: 0.5000 - val_loss: 0.7039\n",
      "Epoch 2/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.7036 - val_accuracy: 0.5000 - val_loss: 0.7005\n",
      "Epoch 3/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.6994 - val_accuracy: 0.5000 - val_loss: 0.6951\n",
      "Epoch 4/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.6982 - val_accuracy: 0.5000 - val_loss: 0.7006\n",
      "Epoch 5/5\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.6987 - val_accuracy: 0.5000 - val_loss: 0.7023\n",
      "\n",
      "ğŸ”¹ Fine-tuning the entire model...\n",
      "\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 0.6979 - val_accuracy: 0.5000 - val_loss: 0.6990\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 24s/step - accuracy: 0.5000 - loss: 0.6879 - val_accuracy: 0.5000 - val_loss: 0.7007\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 16s/step - accuracy: 0.6000 - loss: 0.6945 - val_accuracy: 0.6500 - val_loss: 0.6926\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 18s/step - accuracy: 0.9500 - loss: 0.6674 - val_accuracy: 0.5500 - val_loss: 0.6918\n",
      "Epoch 10/10\n",
      "\u001b[1m1/3\u001b[0m \u001b[32mâ”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:29\u001b[0m 45s/step - accuracy: 0.8750 - loss: 0.6687"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# EXPERIMENT: Transfer Learning using Pre-trained VGG16 Model\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1ï¸âƒ£ Define dataset path\n",
    "base_dir = r'C:\\Users\\Acer\\Desktop\\lp4'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "\n",
    "# 2ï¸âƒ£ Clean and recreate dummy folders\n",
    "import shutil\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "if os.path.exists(valid_dir):\n",
    "    shutil.rmtree(valid_dir)\n",
    "\n",
    "for folder in ['train/cats', 'train/dogs', 'valid/cats', 'valid/dogs']:\n",
    "    os.makedirs(os.path.join(base_dir, folder), exist_ok=True)\n",
    "\n",
    "# 3ï¸âƒ£ Generate dummy images\n",
    "for subdir in ['train/cats', 'train/dogs', 'valid/cats', 'valid/dogs']:\n",
    "    for i in range(10):\n",
    "        arr = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "        Image.fromarray(arr).save(os.path.join(base_dir, subdir, f'{i}.jpg'))\n",
    "\n",
    "print(\"âœ… Dummy dataset created successfully at:\", base_dir)\n",
    "\n",
    "# 4ï¸âƒ£ Create data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(224, 224), batch_size=8, class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    valid_dir, target_size=(224, 224), batch_size=8, class_mode='categorical')\n",
    "\n",
    "# âœ… Automatically get number of classes from generator\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(f\"Detected {num_classes} classes: {list(train_generator.class_indices.keys())}\")\n",
    "\n",
    "# 5ï¸âƒ£ Load base VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 6ï¸âƒ£ Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 7ï¸âƒ£ Compile and train the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nğŸ”¹ Training only new classifier layers...\\n\")\n",
    "model.fit(train_generator, epochs=5, validation_data=validation_generator)\n",
    "\n",
    "# ğŸ”Ÿ Fine-tuning (unfreeze)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nğŸ”¹ Fine-tuning the entire model...\\n\")\n",
    "model.fit(train_generator, epochs=10, initial_epoch=5, validation_data=validation_generator)\n",
    "\n",
    "# 1ï¸âƒ£1ï¸âƒ£ Save model\n",
    "model.save(os.path.join(base_dir, \"vgg16_finetuned.h5\"))\n",
    "print(\"\\nâœ… Model training complete and saved as 'vgg16_finetuned.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "021c55fa-6dce-4632-9bb9-d11f52093d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Desktop\\lp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ca2b1-d24a-422d-8821-48d196c3ee0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
